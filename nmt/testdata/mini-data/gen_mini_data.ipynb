{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cn_chars=list('白日依山尽黄河入海流')\n",
    "jp_chars=list('東京八王子市大和田町')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['佋', '仑', '丮侑', '乹', '于万乇', '亷伭丱', '伕丠乷', '丳', '伕个伒', '伕乳京']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dict=pickle.load(open('../../utils/dicts/comp_dict.pkl',\"rb\"))\n",
    "tr_dict = dict(zip(tr_dict.values(),tr_dict.keys()))\n",
    "[tr_dict[w] for w in cn_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in ['char', 'comp', 'stroke']:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    split = {'train': 200000, 'test': 200, 'dev': 200}\n",
    "    if d == 'char':\n",
    "        for s in split:\n",
    "            cn, jp = gen_data(split[s], 15, cn_chars, jp_chars)\n",
    "            with open(\n",
    "                    os.path.join(d, s + '.cn'), 'wt',\n",
    "                    encoding='utf-8') as fout:\n",
    "                fout.writelines(l + '\\n' for l in cn)\n",
    "            with open(\n",
    "                    os.path.join(d, s + '.jp'), 'wt',\n",
    "                    encoding='utf-8') as fout:\n",
    "                fout.writelines(l + '\\n' for l in jp)\n",
    "    elif d == 'comp':\n",
    "        tr_dict = pickle.load(open('../../utils/dicts/comp_dict.pkl', \"rb\"))\n",
    "        tr_dict = dict(zip(tr_dict.values(), tr_dict.keys()))\n",
    "        for s in split:\n",
    "            cn, jp = gen_data(split[s], 15, cn_chars, jp_chars, tr_dict)\n",
    "            with open(\n",
    "                    os.path.join(d, s + '.cn'), 'wt',\n",
    "                    encoding='utf-8') as fout:\n",
    "                fout.writelines(l + '\\n' for l in cn)\n",
    "            with open(\n",
    "                    os.path.join(d, s + '.jp'), 'wt',\n",
    "                    encoding='utf-8') as fout:\n",
    "                fout.writelines(l + '\\n' for l in jp)\n",
    "    elif d == 'stroke':\n",
    "        tr_dict = pickle.load(open('../../utils/dicts/stroke_dict.pkl', \"rb\"))\n",
    "        tr_dict = dict(zip(tr_dict.values(), tr_dict.keys()))\n",
    "        for s in split:\n",
    "            cn, jp = gen_data(split[s], 15, cn_chars, jp_chars, tr_dict)\n",
    "            with open(\n",
    "                    os.path.join(d, s + '.cn'), 'wt',\n",
    "                    encoding='utf-8') as fout:\n",
    "                fout.writelines(l + '\\n' for l in cn)\n",
    "            with open(\n",
    "                    os.path.join(d, s + '.jp'), 'wt',\n",
    "                    encoding='utf-8') as fout:\n",
    "                fout.writelines(l + '\\n' for l in jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(num_lines,\n",
    "             max_len,\n",
    "             src_chars,\n",
    "             tgt_chars,\n",
    "             tr_dict=None):\n",
    "    src_lines, tgt_lines = [], []\n",
    "    for i in range(num_lines):\n",
    "        random_idx = [\n",
    "            random.randint(0, len(src_chars)-1)\n",
    "            for i in range(random.randint(1, max_len))\n",
    "        ]\n",
    "        if not tr_dict:\n",
    "            src_lines.append(\" \".join([src_chars[i] for i in random_idx]))\n",
    "            tgt_lines.append(\" \".join([tgt_chars[i] for i in reversed(random_idx)]))\n",
    "        else:\n",
    "            src_lines.append(\" \".join([tr_dict[src_chars[i]] for i in random_idx]))\n",
    "            tgt_lines.append(\" \".join([tr_dict[tgt_chars[i]] for i in reversed(random_idx)]))\n",
    "    return src_lines, tgt_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['丟个_1 丟丂個下下 丩丩丌下倆丂俿下 俿下丠个丩丩 丟个_1 丩丩丌下倆丂俿下 俿下丠个丩丩 丂倂丂 下丂丂下丂個下丂下丫丩 丂個下下_1 丟个_1 丟丂丩下丟倅丟个 下丂丂下丂個下丂下丫丩 俿下丠个丩丩 丩丩丌丟下個倂下丩丩',\n",
       "  '下丂丂下丂個下丂下丫丩 丂個下下_1 丟个_1 丩丩丌下懺丩丠丂倃 俿下丠个丩丩 丩丩丌下懺丩丠丂倃 丩丩丌下懺丩丠丂倃 丂個下下_1 丟丂個下下 丂倂丂',\n",
       "  '丂個下下_1 丩丩丌下懺丩丠丂倃 丂倂丂 丩丩丌下懺丩丠丂倃 丂倂丂 丟丂丩下丟倅丟个 丟个_1 丩丩丌下懺丩丠丂倃 丟丂個下下 丟丂個下下 丩丩丌丟下個倂下丩丩',\n",
       "  '丩丩丌丟下個倂下丩丩 丟丂丩下丟倅丟个 下丂丂下丂個下丂下丫丩 丂倂丂 俿下丠个丩丩 丟个_1 丂倂丂 丂個下下_1 丂個下下_1 丩丩丌丟下個倂下丩丩 丩丩丌丟下個倂下丩丩 丟丂個下下',\n",
       "  '丟个_1 丟丂丩下丟倅丟个 丟丂丩下丟倅丟个 俿下丠个丩丩 丩丩丌下倆丂俿下 丩丩丌丟下個倂下丩丩 丟丂丩下丟倅丟个 下丂丂下丂個下丂下丫丩 丟丂個下下 丩丩丌丟下個倂下丩丩 丩丩丌下懺丩丠丂倃 丟丂個下下',\n",
       "  '丟丂丩下丟倅丟个 丂倂丂 丩丩丌下倆丂俿下 丟个_1 丟丂丩下丟倅丟个 丩丩丌下懺丩丠丂倃 丟个_1 丩丩丌下倆丂俿下 丟丂個下下 丩丩丌丟下個倂下丩丩',\n",
       "  '丩丩丌下懺丩丠丂倃 丩丩丌下懺丩丠丂倃 丂倂丂 俿下丠个丩丩 俿下丠个丩丩 丩丩丌丟下個倂下丩丩 丩丩丌下倆丂俿下 丟丂個下下 下丂丂下丂個下丂下丫丩 丩丩丌丟下個倂下丩丩 丟个_1 丟丂個下下 丟个_1 丟丂個下下 下丂丂下丂個下丂下丫丩',\n",
       "  '丟丂個下下 俿下丠个丩丩 丩丩丌下倆丂俿下 俿下丠个丩丩 丩丩丌丟下個倂下丩丩 丩丩丌丟下個倂下丩丩 丩丩丌下懺丩丠丂倃 丂個下下_1 下丂丂下丂個下丂下丫丩 丂個下下_1 丟个_1',\n",
       "  '丩丩丌丟下個倂下丩丩 丂個下下_1 俿下丠个丩丩 俿下丠个丩丩 丟丂個下下 丟丂個下下 丩丩丌下倆丂俿下 下丂丂下丂個下丂下丫丩 丂個下下_1 丟个_1 丩丩丌下倆丂俿下',\n",
       "  '丂個下下_1 下丂丂下丂個下丂下丫丩 丩丩丌丟下個倂下丩丩 丟个_1 丟丂個下下 丩丩丌下倆丂俿下 丩丩丌下倆丂俿下'],\n",
       " ['丟下丂丟丩丂俿下 下丂個下下丂丟个 下丠个_2 倀倆下 丟下丂丟丩丂俿下 下丠个_2 倀倆下 下下丂下_2 丩下丂個丂 丩下丂俿下倆丫丩 丟下丂丟丩丂俿下 丟个_2 丩下丂個丂 倀倆下 丂個下丂下_2',\n",
       "  '丩下丂個丂 丩下丂俿下倆丫丩 丟下丂丟丩丂俿下 丂個下丂下下倆_1 倀倆下 丂個下丂下下倆_1 丂個下丂下下倆_1 丩下丂俿下倆丫丩 下丂個下下丂丟个 下下丂下_2',\n",
       "  '丩下丂俿下倆丫丩 丂個下丂下下倆_1 下下丂下_2 丂個下丂下下倆_1 下下丂下_2 丟个_2 丟下丂丟丩丂俿下 丂個下丂下下倆_1 下丂個下下丂丟个 下丂個下下丂丟个 丂個下丂下_2',\n",
       "  '丂個下丂下_2 丟个_2 丩下丂個丂 下下丂下_2 倀倆下 丟下丂丟丩丂俿下 下下丂下_2 丩下丂俿下倆丫丩 丩下丂俿下倆丫丩 丂個下丂下_2 丂個下丂下_2 下丂個下下丂丟个',\n",
       "  '丟下丂丟丩丂俿下 丟个_2 丟个_2 倀倆下 下丠个_2 丂個下丂下_2 丟个_2 丩下丂個丂 下丂個下下丂丟个 丂個下丂下_2 丂個下丂下下倆_1 下丂個下下丂丟个',\n",
       "  '丟个_2 下下丂下_2 下丠个_2 丟下丂丟丩丂俿下 丟个_2 丂個下丂下下倆_1 丟下丂丟丩丂俿下 下丠个_2 下丂個下下丂丟个 丂個下丂下_2',\n",
       "  '丂個下丂下下倆_1 丂個下丂下下倆_1 下下丂下_2 倀倆下 倀倆下 丂個下丂下_2 下丠个_2 下丂個下下丂丟个 丩下丂個丂 丂個下丂下_2 丟下丂丟丩丂俿下 下丂個下下丂丟个 丟下丂丟丩丂俿下 下丂個下下丂丟个 丩下丂個丂',\n",
       "  '下丂個下下丂丟个 倀倆下 下丠个_2 倀倆下 丂個下丂下_2 丂個下丂下_2 丂個下丂下下倆_1 丩下丂俿下倆丫丩 丩下丂個丂 丩下丂俿下倆丫丩 丟下丂丟丩丂俿下',\n",
       "  '丂個下丂下_2 丩下丂俿下倆丫丩 倀倆下 倀倆下 下丂個下下丂丟个 下丂個下下丂丟个 下丠个_2 丩下丂個丂 丩下丂俿下倆丫丩 丟下丂丟丩丂俿下 下丠个_2',\n",
       "  '丩下丂俿下倆丫丩 丩下丂個丂 丂個下丂下_2 丟下丂丟丩丂俿下 下丂個下下丂丟个 下丠个_2 下丠个_2'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data(10,15,cn_chars,jp_chars,tr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-12-058644f17612>\u001b[0m(11)\u001b[0;36mgen_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      9 \u001b[1;33m        random_idx = [\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m            \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_chars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 11 \u001b[1;33m            \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        ]\n",
      "\u001b[0m\u001b[1;32m     13 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msrc_tr_dict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtgt_tr_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> i\n",
      "0\n",
      "ipdb> u\n",
      "> \u001b[1;32m<ipython-input-13-8fcef51a7060>\u001b[0m(1)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m----> 1 \u001b[1;33m\u001b[0mgen_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcn_chars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjp_chars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> s\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
